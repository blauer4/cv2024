{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames in the video:  2584\n"
     ]
    }
   ],
   "source": [
    "camera_number = 1\n",
    "frame_count = 0\n",
    "image_number = 10\n",
    "\n",
    "#print(os.listdir())\n",
    "\n",
    "abs_dir_path = \"videos/\"\n",
    "VIDEO_NAME = f'out{camera_number}F.mp4'\n",
    "ROW_POINTS = 5\n",
    "COLUMNS_POINTS = 7\n",
    "# Open the video file \n",
    "video_capture = cv2.VideoCapture(filename=f'{abs_dir_path}{VIDEO_NAME}')\n",
    "\n",
    "# Print the number of frames in the video\n",
    "number_of_frame = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Number of frames in the video: \", number_of_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['videos',\n",
       " 'README.md',\n",
       " '__pycache__',\n",
       " 'Calibration.pdf',\n",
       " 'CVprojects-Sport.pdf',\n",
       " 'Rizzetto-Tomaselli_Report.pdf',\n",
       " '.git',\n",
       " 'chessboard_calibration.py',\n",
       " 'Accuracy_Evaluation_and_Prediction_of_Single-Image_Camera_Calibration.pdf',\n",
       " 'LICENSE',\n",
       " 'samples',\n",
       " 'report',\n",
       " '.gitignore',\n",
       " 'lib',\n",
       " 'checkboard_test.ipynb',\n",
       " 'appunti']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()\n",
    "#os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving frames to  samples/out1\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to save the screen captures named as the video file\n",
    "output_dir = 'samples/' + f'out{camera_number}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"Saving frames to \", output_dir)\n",
    "# Remove all files in the directory\n",
    "for file in os.listdir(output_dir):\n",
    "    os.remove(os.path.join(output_dir, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting skip of 500\n",
      "frame after skip\n",
      "[[ 581.54016 1488.0059 ]]\n",
      "saving images to directory\n",
      "all flags time: 1435.2750000059605\n",
      "True\n",
      "[[ 581.54016 1488.0059 ]]\n",
      "saving images to directory\n",
      "no flags time: 1227.6939999982715\n",
      "True\n",
      "[[ 580.76636 1487.8502 ]]\n",
      "saving images to directory\n",
      "no norm flag time: 1193.752999998629\n",
      "True\n",
      "only fast flag time: 606.9409999996424\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#findChessboard Flag test\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "import cv2 \n",
    "\n",
    "one = cal.Calibration(video_path, CHESS_WIDTH, CHESS_HEIGHT)\n",
    "skip = 500\n",
    "img = []\n",
    "print(f'starting skip of {skip}')\n",
    "for i in range(skip):\n",
    "    ret, img = one.video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "print(f'frame after skip')\n",
    "\n",
    "cv2.namedWindow(\"test image\", cv2.WINDOW_NORMAL) \n",
    "  \n",
    "# Using resizeWindow() \n",
    "cv2.resizeWindow(\"test image\", 1920, 1080) \n",
    "  \n",
    "# Displaying the image \n",
    "cv2.imshow(\"test image\", img) \n",
    "\n",
    "one.video_capture.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#flags FAST_CHECK -> False FAST_CHECK + NORMALIZE -> False  None -> True FAST_CHECK + NORMALIZE + THRESH \n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "ret, imgpoints = one.extractCorners(img= img, output_dir= 'test/', find_flags=  cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "print(f\"all flags time: {(t2 - timestamp)}\")\n",
    "print(ret)\n",
    "\n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "#print(timestamp)\n",
    "ret, imgpoints = one.extractCorners(img= img, output_dir= 'test/', find_flags=  None)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "#print(t2)\n",
    "print(f\"no flags time: {(t2 - timestamp)}\")\n",
    "print(ret)\n",
    "\n",
    "##best one!\n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "#print(timestamp)\n",
    "ret, imgpoints = one.extractCorners(img= img, output_dir= 'test/', find_flags=  cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "#print(t2)\n",
    "print(f\"no norm flag time: {(t2 - timestamp)}\")\n",
    "print(ret)\n",
    "\n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "#print(timestamp)\n",
    "ret, imgpoints = one.extractCorners(img= img, output_dir= 'test/', find_flags= cv2.CALIB_CB_FAST_CHECK)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "#print(t2)\n",
    "print(f\"only fast flag time: {(t2 - timestamp)}\")\n",
    "print(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:00<00:00,  1.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#COMPUTING INTRINSIC PARAMETERS TEST\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "from tqdm import tqdm\n",
    "\n",
    "camera = 'out2F'\n",
    "input_dir = f'samples/{camera}'\n",
    "all_chessboard_sizes = [(5, 7), (5, 7), (5, 7), (5, 7), (6, 9), (6, 9), (5, 7), (6, 9), (6, 9), (0, 0), (6, 9), (5, 7),\n",
    "                        (5, 7)]\n",
    "chessboard_size = all_chessboard_sizes[int(re.search('\\d',camera)[0])]\n",
    "\n",
    "CHESS_WIDTH = chessboard_size[0]\n",
    "CHESS_HEIGHT = chessboard_size[1]\n",
    "\n",
    "\n",
    "img_list = util.loadImagesBatch(input_dir)\n",
    "img_size =  ((img_list[0]).shape[1], (img_list[0]).shape[0]) #width and height\n",
    "imgpoints = []\n",
    "objpoints = []\n",
    "\n",
    "objp = np.zeros((CHESS_WIDTH * CHESS_HEIGHT, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESS_WIDTH, 0:CHESS_HEIGHT].T.reshape(-1, 2)\n",
    "\n",
    "\n",
    "for img in tqdm(img_list):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, points = cv2.findChessboardCorners(gray,(CHESS_WIDTH, CHESS_HEIGHT),None, cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_ADAPTIVE_THRESH)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(points)\n",
    "\n",
    "#no subpixel cases\n",
    "\n",
    "    #tc std.\n",
    "tc = (cv2.TERM_CRITERIA_EPS, 0.005)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size , None, tc)\n",
    "json_camera_matrix = {\n",
    "        'ret' : ret,\n",
    "        'mtx' : mtx.tolist(),\n",
    "        'dist': dist.tolist(),\n",
    "        'rvecs' : [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "        'tvecs' : [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(json_camera_matrix, f'{camera}std')\n",
    "    #tc high accuracy\n",
    "tc = (cv2.TERM_CRITERIA_EPS, 0.00001)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size , None, tc)\n",
    "json_camera_matrix = {\n",
    "        'ret' : ret,\n",
    "        'mtx' : mtx.tolist(),\n",
    "        'dist': dist.tolist(),\n",
    "        'rvecs' : [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "        'tvecs' : [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(json_camera_matrix, f'{camera}high_acc')\n",
    "    #tc high accuracy and iteration\n",
    "tc = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 0.005, 50)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size , None, tc)\n",
    "json_camera_matrix = {\n",
    "        'ret' : ret,\n",
    "        'mtx' : mtx.tolist(),\n",
    "        'dist': dist.tolist(),\n",
    "        'rvecs' : [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "        'tvecs' : [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(json_camera_matrix, f'{camera}iter')\n",
    "\n",
    "#subpixel refinement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy matrix: [[2.04228338e+03 0.00000000e+00 1.96746787e+03]\n",
      " [0.00000000e+00 2.04802155e+03 1.17392187e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UNDISTORTION TEST\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "\n",
    "camera = 'out2F'\n",
    "image = 'chessboard55'\n",
    "\n",
    "und_dir = f'undistorted/{camera}'\n",
    "os.makedirs(und_dir, exist_ok=True)\n",
    "\n",
    "filepath = f'samples/{camera}/{image}.jpg'\n",
    "img = cv2.imread(filename=filepath)\n",
    "\n",
    "#showing original image\n",
    "util.showImage(img, 'original')\n",
    "\n",
    "#refining camera matrix\n",
    "dict = util.LoadJSON('json/out2Fhigh_acccorners.json')\n",
    "h, w = img.shape[:2]\n",
    "#standard values, taken from the json\n",
    "std_mtx = np.array(dict['mtx'])\n",
    "std_dist = np.array(dict['dist'])\n",
    "print(f\"numpy matrix: {std_mtx}\")\n",
    "new_mtx, roi = cv2.getOptimalNewCameraMatrix(std_mtx, std_dist, (w,h), 1, (w,h))\n",
    "\n",
    "x, y, w, h = roi\n",
    "\n",
    "#undistort the image, corrected with the new computed camera matrix\n",
    "new_dist = np.array([])\n",
    "und_img = cv2.undistort(src=img, cameraMatrix= std_mtx, dst= new_dist ,distCoeffs= std_dist, newCameraMatrix= new_mtx)\n",
    "util.showImage(und_img, 'undistorted - new camera matrix - no crop')\n",
    "cv2.imwrite(f'{und_dir}/{camera}_new_mtx_no.jpg',und_img)\n",
    "#print((np.size(np.array(und_img),0),np.size(np.array(und_img),1)))\n",
    "# crop\n",
    "crop_und_img = und_img[y:y+h, x:x+w]\n",
    "util.showImage(crop_und_img, 'undistorted - new camera matrix - cropped')\n",
    "cv2.imwrite(f'{und_dir}/{camera}_new_mtx.jpg', crop_und_img)\n",
    "#no new camera matrix\n",
    "und_img = cv2.undistort(src=img, cameraMatrix= std_mtx, dst= new_dist ,distCoeffs= std_dist)\n",
    "util.showImage(und_img, 'undistorted - standard camera matrix - no crop')\n",
    "cv2.imwrite(f'{und_dir}/{camera}_std_mtx.jpg',und_img)\n",
    "# crop \n",
    "# no_crop_und_img = und_img[y:y+h, x:x+w]\n",
    "#util.showImage(und_img, 'undistorted - standard camera matrix - cropped')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "saving to JSON\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "saving to JSON\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "##JSON TEST\n",
    "frame_skip = 10\n",
    "for i in range(1400):\n",
    "    ret, img = video_capture.read()\n",
    "\n",
    "json_dict = {}\n",
    "\n",
    "while True:\n",
    "        # Read a frame from the video\n",
    "        ret, img = video_capture.read()\n",
    "        if not ret:\n",
    "            break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "        # Skip frames based on the frame_skip value\n",
    "        if frame_count % frame_skip == 0 :\n",
    "            # Resize the frame to the new_resolution\n",
    "            real_img = img\n",
    "            \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #corners = []\n",
    "            # Find the chessboard corners\n",
    "            found_corners, corners = cv2.findChessboardCorners(gray, (ROW_POINTS, COLUMNS_POINTS), corners= None)\n",
    "            #res_img = cv2.drawChessboardCorners(img,(ROW_POINTS,COLUMNS_POINTS),corners,found_corners)\n",
    "            if found_corners:\n",
    "                #populating the dictionary with the points\n",
    "                print('saving to JSON')\n",
    "                json_dict.update([[f\"{camera_number}_{1000 + frame_count}\" , corners.tolist()]])\n",
    "            print(frame_count)\n",
    "        \n",
    "            #print(\"Frame \", frame_count, \":\", found_corners)\n",
    "            #res_img = cv2.cvtColor(res_img, cv2.COLOR_GRAY2BGR)\n",
    "        frame_count += 1  \n",
    "        if frame_count == 300:\n",
    "            break  \n",
    "\n",
    "res = saveToJSON(json_dict, camera_number)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveToJSON(np.array([[12,3],[3,3]]),1,210)\n",
    "saveToJSON(np.array([[12,3],[3,3]]),2,100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
