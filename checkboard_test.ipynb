{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "camera_number = 1\n",
    "frame_count = 0\n",
    "image_number = 10\n",
    "\n",
    "#print(os.listdir())\n",
    "\n",
    "abs_dir_path = \"videos/\"\n",
    "VIDEO_NAME = f'out{camera_number}F.mp4'\n",
    "ROW_POINTS = 5\n",
    "COLUMNS_POINTS = 7\n",
    "# Open the video file \n",
    "video_capture = cv2.VideoCapture(filename=f'{abs_dir_path}{VIDEO_NAME}')\n",
    "\n",
    "# Print the number of frames in the video\n",
    "number_of_frame = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Number of frames in the video: \", number_of_frame)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.listdir()\n",
    "#os.chdir('..')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a directory to save the screen captures named as the video file\n",
    "output_dir = 'samples/' + f'out{camera_number}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"Saving frames to \", output_dir)\n",
    "# Remove all files in the directory\n",
    "for file in os.listdir(output_dir):\n",
    "    os.remove(os.path.join(output_dir, file))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#findChessboard Flag test\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "import cv2\n",
    "\n",
    "video_path = '...'\n",
    "width = 0\n",
    "height = 0\n",
    "\n",
    "one = cal.Calibration(video_path, width, height)\n",
    "skip = 500\n",
    "img = []\n",
    "print(f'starting skip of {skip}')\n",
    "for i in range(skip):\n",
    "    ret, img = one.video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "print(f'frame after skip')\n",
    "\n",
    "cv2.namedWindow(\"test image\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Using resizeWindow() \n",
    "cv2.resizeWindow(\"test image\", 1920, 1080)\n",
    "\n",
    "# Displaying the image \n",
    "cv2.imshow(\"test image\", img)\n",
    "\n",
    "one.video_capture.release()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#flags FAST_CHECK -> False FAST_CHECK + NORMALIZE -> False  None -> True FAST_CHECK + NORMALIZE + THRESH \n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "ret, imgpoints = one.extractCorners(img=img, output_dir='test/',\n",
    "                                    find_flags=cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "print(f\"all flags time: {(t2 - timestamp)}\")\n",
    "print(ret)\n",
    "\n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "#print(timestamp)\n",
    "ret, imgpoints = one.extractCorners(img=img, output_dir='test/', find_flags=None)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "#print(t2)\n",
    "print(f\"no flags time: {(t2 - timestamp)}\")\n",
    "print(ret)\n",
    "\n",
    "##best one!\n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "#print(timestamp)\n",
    "ret, imgpoints = one.extractCorners(img=img, output_dir='test/',\n",
    "                                    find_flags=cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "#print(t2)\n",
    "print(f\"no norm flag time: {(t2 - timestamp)}\")\n",
    "print(ret)\n",
    "\n",
    "now = dt.datetime.now()\n",
    "timestamp = util.getSeconds(now)\n",
    "#print(timestamp)\n",
    "ret, imgpoints = one.extractCorners(img=img, output_dir='test/', find_flags=cv2.CALIB_CB_FAST_CHECK)\n",
    "now = dt.datetime.now()\n",
    "t2 = util.getSeconds(now)\n",
    "#print(t2)\n",
    "print(f\"only fast flag time: {(t2 - timestamp)}\")\n",
    "print(ret)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#COMPUTING INTRINSIC PARAMETERS TEST\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "from tqdm import tqdm\n",
    "\n",
    "camera = 'out6F'\n",
    "input_dir = f'samples/{camera}'\n",
    "all_chessboard_sizes = [(5, 7), (5, 7), (5, 7), (5, 7), (6, 9), (6, 9), (5, 7), (6, 9), (6, 9), (0, 0), (6, 9), (5, 7),\n",
    "                        (5, 7)]\n",
    "chessboard_size = all_chessboard_sizes[int(re.search('\\d', camera)[0]) - 1]\n",
    "\n",
    "CHESS_WIDTH = chessboard_size[0]\n",
    "CHESS_HEIGHT = chessboard_size[1]\n",
    "\n",
    "img_list = util.loadImagesBatch(input_dir)\n",
    "img_size = ((img_list[0]).shape[1], (img_list[0]).shape[0])  #width and height\n",
    "imgpoints = []\n",
    "objpoints = []\n",
    "print(img_size)\n",
    "objp = np.zeros((CHESS_WIDTH * CHESS_HEIGHT, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESS_WIDTH, 0:CHESS_HEIGHT].T.reshape(-1, 2)\n",
    "\n",
    "for img in tqdm(img_list):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, points = cv2.findChessboardCorners(gray, (CHESS_WIDTH, CHESS_HEIGHT), None,\n",
    "                                            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_ADAPTIVE_THRESH)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(points)\n",
    "\n",
    "print(f'first imgpoints: {imgpoints[0]}')\n",
    "#no subpixel cases\n",
    "\n",
    "#tc std.\n",
    "tc = (cv2.TERM_CRITERIA_EPS, 0.005)\n",
    "print(f'tcstd{tc}')\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, tc)\n",
    "json_camera_matrix = {\n",
    "    'ret': ret,\n",
    "    'mtx': mtx.tolist(),\n",
    "    'dist': dist.tolist(),\n",
    "    'rvecs': [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "    'tvecs': [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(json_camera_matrix, f'{camera}std')\n",
    "#tc high accuracy\n",
    "tc = (cv2.TERM_CRITERIA_EPS, 0.00001)\n",
    "print(f'tchigh{tc}')\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, tc)\n",
    "json_camera_matrix = {\n",
    "    'ret': ret,\n",
    "    'mtx': mtx.tolist(),\n",
    "    'dist': dist.tolist(),\n",
    "    'rvecs': [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "    'tvecs': [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(json_camera_matrix, f'{camera}high_acc')\n",
    "#tc high accuracy and iteration\n",
    "tc = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 0.005, 50)\n",
    "print(f'tccombine{tc}')\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, tc)\n",
    "json_camera_matrix = {\n",
    "    'ret': ret,\n",
    "    'mtx': mtx.tolist(),\n",
    "    'dist': dist.tolist(),\n",
    "    'rvecs': [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "    'tvecs': [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(json_camera_matrix, f'{camera}iter')\n",
    "\n",
    "#subpixel refinement\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#UNDISTORTION TEST\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "\n",
    "camera = 'out6F'\n",
    "image = 'chessboard10'\n",
    "\n",
    "und_dir = f'undistorted/{camera}'\n",
    "os.makedirs(und_dir, exist_ok=True)\n",
    "\n",
    "# Remove all files in the directory\n",
    "for file in os.listdir(und_dir):\n",
    "    os.remove(os.path.join(und_dir, file))\n",
    "\n",
    "filepath = f'samples/{camera}/{image}.jpg'\n",
    "img = cv2.imread(filename=filepath)\n",
    "\n",
    "#showing original image\n",
    "util.showImage(img, 'original')\n",
    "\n",
    "#refining camera matrix\n",
    "path = '6Fcorners.json'\n",
    "dict = util.LoadJSON(path)\n",
    "h, w = img.shape[:2]\n",
    "#standard values, taken from the json\n",
    "std_mtx = np.array(dict['mtx'])\n",
    "std_dist = np.array(dict['dist'])\n",
    "print(f\"numpy matrix: {std_mtx}\")\n",
    "new_mtx, roi = cv2.getOptimalNewCameraMatrix(std_mtx, std_dist, (w, h), 1, (w, h))\n",
    "\n",
    "x, y, w, h = roi\n",
    "\n",
    "#undistort the image, corrected with the new computed camera matrix\n",
    "new_dist = np.array([])\n",
    "und_img = cv2.undistort(src=img, cameraMatrix=std_mtx, dst=new_dist, distCoeffs=std_dist, newCameraMatrix=new_mtx)\n",
    "util.showImage(und_img, 'undistorted - new camera matrix - no crop')\n",
    "cv2.imwrite(f'{und_dir}/{camera}_new_mtx_no.jpg', und_img)\n",
    "#print((np.size(np.array(und_img),0),np.size(np.array(und_img),1)))\n",
    "# crop\n",
    "crop_und_img = und_img[y:y + h, x:x + w]\n",
    "util.showImage(crop_und_img, 'undistorted - new camera matrix - cropped')\n",
    "cv2.imwrite(f'{und_dir}/{camera}_new_mtx.jpg', crop_und_img)\n",
    "#no new camera matrix\n",
    "und_img = cv2.undistort(src=img, cameraMatrix=std_mtx, dst=new_dist, distCoeffs=std_dist)\n",
    "util.showImage(und_img, 'undistorted - standard camera matrix - no crop')\n",
    "cv2.imwrite(f'{und_dir}/{camera}_std_mtx.jpg', und_img)\n",
    "# crop \n",
    "# no_crop_und_img = und_img[y:y+h, x:x+w]\n",
    "#util.showImage(und_img, 'undistorted - standard camera matrix - cropped')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#image ordered calibration tests \n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "from tqdm import tqdm\n",
    "\n",
    "camera = 'out2F'\n",
    "input_dir = f'samples/{camera}'\n",
    "all_chessboard_sizes = [(5, 7), (5, 7), (5, 7), (5, 7), (6, 9), (6, 9), (5, 7), (6, 9), (6, 9), (0, 0), (6, 9), (5, 7),\n",
    "                        (5, 7)]\n",
    "chessboard_size = all_chessboard_sizes[int(re.search('\\d', camera)[0]) - 1]\n",
    "\n",
    "CHESS_WIDTH = chessboard_size[0]\n",
    "CHESS_HEIGHT = chessboard_size[1]\n",
    "\n",
    "img_list = util.loadImagesBatch(input_dir)\n",
    "img_list_sorted = util.loadImagesBatch(input_dir, True)\n",
    "\n",
    "img_size = ((img_list[0]).shape[1], (img_list[0]).shape[0])  #width and height\n",
    "imgpoints = []\n",
    "objpoints = []\n",
    "print(img_size)\n",
    "objp = np.zeros((CHESS_WIDTH * CHESS_HEIGHT, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESS_WIDTH, 0:CHESS_HEIGHT].T.reshape(-1, 2)\n",
    "tc = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 0.005, 50)\n",
    "\n",
    "for img in tqdm(img_list):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, points = cv2.findChessboardCorners(gray, (CHESS_WIDTH, CHESS_HEIGHT), None,\n",
    "                                            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_ADAPTIVE_THRESH)\n",
    "    if ret:\n",
    "        #print('found')\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(points)\n",
    "\n",
    "print(f'first imgpoints: {imgpoints[0][0]}')\n",
    "print(len(imgpoints))\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, tc)\n",
    "json_camera_matrix = {\n",
    "    'ret': ret,\n",
    "    'mtx': mtx.tolist(),\n",
    "    'dist': dist.tolist(),\n",
    "    'rvecs': [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "    'tvecs': [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(json_camera_matrix, f'{camera}std_fetching')\n",
    "\n",
    "imgpoints = []\n",
    "objpoints = []\n",
    "\n",
    "for img in tqdm(img_list_sorted):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, points = cv2.findChessboardCorners(gray, (CHESS_WIDTH, CHESS_HEIGHT), None,\n",
    "                                            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_ADAPTIVE_THRESH)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(points)\n",
    "\n",
    "print(f'first imgpoints: {imgpoints[0][0]}')\n",
    "print(len(imgpoints))\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, tc)\n",
    "ordered_json_camera_matrix = {\n",
    "    'ret': ret,\n",
    "    'mtx': mtx.tolist(),\n",
    "    'dist': dist.tolist(),\n",
    "    'rvecs': [rvecs[0].tolist(), rvecs[1].tolist()],\n",
    "    'tvecs': [tvecs[0].tolist(), tvecs[1].tolist()]\n",
    "}\n",
    "util.saveToJSON(ordered_json_camera_matrix, f'{camera}sorted_fetching')\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def progressBar(num: int):\n",
    "    star = '*'\n",
    "    slash = '-'\n",
    "    bar = '['\n",
    "    if num >= 20:\n",
    "        print('[********************]')\n",
    "    for it in range(num):\n",
    "        bar = bar + star\n",
    "    for it in range(20 - num):\n",
    "        bar = bar + slash\n",
    "    bar = bar + ']'\n",
    "    return bar\n",
    "\n",
    "\n",
    "def showProgressBar(iteration: int, condition: int) -> None:\n",
    "    if (iteration >= condition):\n",
    "        print(progressBar(20))\n",
    "    else:\n",
    "        print(progressBar(int((iteration) / (condition / 20))))\n",
    "\n",
    "\n",
    "i = 0\n",
    "while i < 100:\n",
    "    showProgressBar(i, 100)\n",
    "    i += 10\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#solvePnP TEST\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def computeReProjError(objpoints, imgpoints, mtx, dist, rvecs, tvecs):\n",
    "    \"\"\"\n",
    "    method for computing multiple reprojeciton errors.\n",
    "    It returns the average value of the reprojeciton errors, different from the openCv calibrateCamera ret value(which is RMSE)\n",
    "        - objpoints: list of object points in the 3D camera space\n",
    "        - imgpoints: list of image points in the 2D camera plane\n",
    "        - mtx: camera matrix (3x3)\n",
    "        - dist: distorsion values of the camera\n",
    "        - rvecs: list of rotation vectors \n",
    "        - tvecs: list of translation vectors\n",
    "    \"\"\"\n",
    "    mean_error = 0\n",
    "    for i in range(np.shape(objpoints)[0]):\n",
    "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "        mean_error += error / (np.shape(objpoints)[0])\n",
    "    return mean_error\n",
    "\n",
    "\n",
    "def computeMultiplePnP(objpoints, imgpoints, mtx, dist, flags=cv2.SOLVEPNP_ITERATIVE):\n",
    "    tvecs = []\n",
    "    rvecs = []\n",
    "    for i in range(np.shape(objpoints)[0]):\n",
    "        r, rvec, tvec = cv2.solvePnP(objpoints[i], imgpoints[i], mtx, dist, flags)\n",
    "        rvecs.append(rvec)\n",
    "        tvecs.append(tvec)\n",
    "    return (rvecs, tvecs)\n",
    "\n",
    "\n",
    "#Refine case of solvePnP\n",
    "def computeMultipleRefinePnP(objpoints, imgpoints, mtx, dist, rvecs, tvecs):\n",
    "    final_tvecs = []\n",
    "    final_rvecs = []\n",
    "    for i in range(np.shape(objpoints)[0]):\n",
    "        print(rvecs[i])\n",
    "        rvec, tvec = cv2.solvePnPRefineLM(objpoints[i], imgpoints[i], mtx, dist, rvecs[i], tvecs[i])\n",
    "        final_rvecs.append(rvec)\n",
    "        final_tvecs.append(tvec)\n",
    "    return (final_rvecs, final_tvecs)\n",
    "\n",
    "\n",
    "camera = 'out2F'\n",
    "input_dir = f'samples/{camera}'\n",
    "all_chessboard_sizes = [(5, 7), (5, 7), (5, 7), (5, 7), (6, 9), (6, 9), (5, 7), (6, 9), (6, 9), (0, 0), (6, 9), (5, 7),\n",
    "                        (5, 7)]\n",
    "chessboard_size = all_chessboard_sizes[int(re.search('\\d', camera)[0]) - 1]\n",
    "\n",
    "CHESS_WIDTH = chessboard_size[0]\n",
    "CHESS_HEIGHT = chessboard_size[1]\n",
    "\n",
    "img_list = util.loadImagesBatch(input_dir)\n",
    "\n",
    "img_size = ((img_list[0]).shape[1], (img_list[0]).shape[0])  #width and height\n",
    "imgpoints = []\n",
    "objpoints = []\n",
    "print(img_size)\n",
    "objp = np.zeros((CHESS_WIDTH * CHESS_HEIGHT, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHESS_WIDTH, 0:CHESS_HEIGHT].T.reshape(-1, 2)\n",
    "tc = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 0.005, 50)\n",
    "\n",
    "for img in tqdm(img_list):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, points = cv2.findChessboardCorners(gray, (CHESS_WIDTH, CHESS_HEIGHT), None,\n",
    "                                            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_ADAPTIVE_THRESH)\n",
    "    if ret:\n",
    "        #print('found')\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(points)\n",
    "objpoints = np.array(objpoints)\n",
    "imgpoints = np.array(imgpoints)\n",
    "\n",
    "print(f'img: {np.shape(imgpoints)}\\nobj: {np.shape(objpoints)}')\n",
    "\n",
    "#Using std. calibrateCamera method as a base value for comparison\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, tc)\n",
    "#print(f\"ret:{ret}\\nmtx:{mtx}\\ndist:{dist}\\nrvecs:{rvecs}\\ntvecs:{tvecs}\")\n",
    "print(f\"ret:{ret}\")\n",
    "print(f\"rvecs0:{rvecs[0]}\\ntvecs0:{tvecs[0]}\")\n",
    "print(f\"rvecs:{rvecs}\")\n",
    "\n",
    "#using solvePnP (Levenberg-Marquardt optimization), same as calibrateCamera\n",
    "pnp_rvecs, pnp_tvecs = computeMultiplePnP(objpoints, imgpoints, mtx, dist)\n",
    "pnp_tvecs = np.array(pnp_tvecs)\n",
    "pnp_rvecs = np.array(pnp_rvecs)\n",
    "error = computeReProjError(objpoints, imgpoints, mtx, dist, pnp_rvecs, pnp_tvecs)\n",
    "print(f\"tvec1:{pnp_tvecs[0]}\")\n",
    "print(f\"std. result: {error}\")\n",
    "\n",
    "#using solvePnP, coplanar object points(\"Infinitesimal Plane-Based Pose Estimation\")\n",
    "pnp_rvecs, pnp_tvecs = computeMultiplePnP(objpoints, imgpoints, mtx, dist, flags=cv2.SOLVEPNP_IPPE)\n",
    "pnp_tvecs = np.array(pnp_tvecs)\n",
    "pnp_rvecs = np.array(pnp_rvecs)\n",
    "error = computeReProjError(objpoints, imgpoints, mtx, dist, pnp_rvecs, pnp_tvecs)\n",
    "print(f\"tvec2:{pnp_tvecs[0]}\")\n",
    "print(f\"ippe. result: {error}\")\n",
    "\n",
    "###\n",
    "#using \"pose refinement\" methods, as suggested from openCv\n",
    "###\n",
    "\n",
    "#solvePnPRefineLM(), similar to the std. method, doesn't change the result significantly\n",
    "\n",
    "refined_rvecs, refined_tvecs = computeMultipleRefinePnP(objpoints, imgpoints, mtx, dist, rvecs, tvecs)\n",
    "print(f\"refined_tvec: {refined_tvecs[0]}\\nrefined_rvec: {refined_rvecs[0]}\")\n",
    "refined_tvecs = np.array(refined_tvecs)\n",
    "refined_rvecs = np.array(refined_rvecs)\n",
    "error = computeReProjError(objpoints, imgpoints, mtx, dist, refined_rvecs, refined_tvecs)\n",
    "print(f\"refinement. result: {error}\")\n",
    "#solvePnPRefineVVS(), similar to the previous\n",
    "\n",
    "# VVS_rvec, VVS_tvec = cv2.solvePnPRefineVVS(objpoints[0], imgpoints[0], mtx, dist, rvecs[0], tvecs[0] )\n",
    "# print(f\"VVS_tvec: {VVS_tvec}\\nrefined_rvec: {VVS_rvec}\")\n",
    "\n",
    "json_camera_matrix = {\n",
    "    'ret': ret,\n",
    "    'mtx': mtx.tolist(),\n",
    "    'dist': dist.tolist(),\n",
    "    'rvecs': pnp_rvecs.tolist(),\n",
    "    'tvecs': pnp_tvecs.tolist()\n",
    "}\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "file = open('../CV-CameraCalibration/camera_parameters/without_crop/out6F.p', 'rb')\n",
    "structure = pickle.load(file)\n",
    "\n",
    "print(structure)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import datetime as dt\n",
    "import lib.util as util\n",
    "import lib.Calibration as cal\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Flag:\n",
    "    f = True\n",
    "\n",
    "    def __init__(self, value: bool):\n",
    "        self.f = value\n",
    "\n",
    "    def change(self):\n",
    "        self.f = not self.f\n",
    "\n",
    "\n",
    "video_path = '../videos/out1.mp4'\n",
    "width = 0\n",
    "height = 0\n",
    "\n",
    "\n",
    "def mouseCallback(event, x, y, flags, params):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # print(f\"event:{event}\\nx:{x}\\ny:{y}\\nevent:{flags}\")\n",
    "        point = input('Enter point name:')\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, f'{point}', (x, y), font, 1, (0, 0, 0), 3)\n",
    "        cv2.circle(img, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.imshow('frame1', img)\n",
    "\n",
    "\n",
    "def callbackButton(state, userdata):\n",
    "    w_name, flag = userdata\n",
    "    if flag.f:\n",
    "        cv2.setMouseCallback(w_name, mouseCallback)\n",
    "    else:\n",
    "        cv2.setMouseCallback(w_name, lambda *args: None)\n",
    "    flag.change()\n",
    "\n",
    "\n",
    "def showImage(img, window_name: str):\n",
    "    \"\"\"\n",
    "    Takes an image and show it in a fixed size window, press a button to close it in the end\n",
    "        - img: An image to be shown\n",
    "        - window_name: the name of the window where displaying the image\n",
    "    \"\"\"\n",
    "    # show the original image\n",
    "    w_name = window_name\n",
    "    cv2.namedWindow(w_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    flag = Flag(True)\n",
    "\n",
    "    cv2.createButton('select_pixel', callbackButton, (w_name, flag))\n",
    "\n",
    "    # Using resizeWindow() \n",
    "    cv2.resizeWindow(w_name, 1920, 1080)\n",
    "    cv2.imshow(w_name, img)\n",
    "    cv2.waitKey(0)\n",
    "    # while cv2.waitKey(33) != ord('a'):\n",
    "    #     cv2.imshow(w_name, img)\n",
    "    cv2.destroyWindow(window_name)\n",
    "\n",
    "\n",
    "one = cal.Calibration(video_path, width, height)\n",
    "skip = 15\n",
    "img = []\n",
    "print(f'starting skip of {skip}')\n",
    "for i in range(skip):\n",
    "    ret, img = one.video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "showImage(img, 'frame1')\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
